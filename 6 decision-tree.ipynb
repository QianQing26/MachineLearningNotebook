{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    ">目标：找到一个衡量标准，来计算不同特征进行分支选择后的分类情况，并且将最好的那个当作根节点，以此类推\n",
    "\n",
    "__衡量标准：熵__\n",
    "\n",
    "熵是表示随机变量不确定性的度量，公式为：\n",
    "$$H(X)=-\\sum_i p_i*log(p_i)$$\n",
    "其中，熵越大，不确定性越高。\n",
    "1. 当$p=0 or 1$的时候，$H(p)=0$，完全没有不确定性性\n",
    "2. 当$p=0.5$的时候，$H(p)$最大，此时变量的不确定性最大\n",
    "\n",
    "在分类任务中，期望通过分类后熵值的减少来评判\n",
    "### 决策树算法\n",
    "__ID3：信息增益__\n",
    "\n",
    "表示特征X使得类Y的不确定性减少的程度（希望分类后的结果是同类在一起）\n",
    "\n",
    "不适合解决稀疏的特征\n",
    "\n",
    "__C4.5:信息增益率__\n",
    "\n",
    "__GINI系数：__\n",
    "和熵类似\n",
    "$$Gini(p)=\\sum_{k=1}^K p_k(1-p_k) = 1-\\sum_{k=1}^Kp_k^2$$\n",
    "\n",
    "### 连续值的处理\n",
    "对连续值进行排序之后，选择可能的分界点（离散化的过程），使用贪心算法寻找效果最好的方法\n",
    "\n",
    "### 剪枝策略\n",
    "为了防止过拟合，进行剪枝\n",
    "\n",
    "__预剪枝__：限制深度、叶子结点个数、叶子节点样本数、信息增益量等\n",
    "\n",
    "__后剪枝__: 建立完决策树之后，通过一定的标准衡量$$C_{\\alpha}(T)=C(T)+\\alpha\\cdot\\left|T_{leaf}\\right|$$(叶子结点越多，损失越大)\n",
    "\n",
    "$\\alpha$是控制计算损失的参数，$\\alpha$越大，则越不容易过拟合\n",
    "\n",
    "### 回归问题\n",
    "回归问题不能使用熵来衡量，可以使用方差，衡量划分的好坏。最后回归值等于归类之后的平均数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import pickle\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 先创建一个数据集\n",
    "def creatDataset():\n",
    "    dataSet = [[0,0,0,0,'no'],\n",
    "               [0,0,0,1,'no'],\n",
    "               [0,1,0,1,'yes'],\n",
    "               [0,1,1,0,'yes'],\n",
    "               [0,0,0,0,'no'],\n",
    "               [1,0,0,0,'no'],\n",
    "               [1,0,0,1,'no'],\n",
    "               [1,1,1,1,'yes'],\n",
    "               [1,0,1,2,'yes'],\n",
    "               [1,0,1,2,'yes'],\n",
    "               [2,0,1,2,'yes'],\n",
    "               [2,0,1,1,'yes'],\n",
    "               [2,1,0,1,'yes'],\n",
    "               [2,1,0,2,'yes'],\n",
    "               [2,0,0,0,'no']]\n",
    "    labels = ['F1-AGE','F2-WORK','F3-HOME','F4-LOAN']\n",
    "    return dataSet,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatTree(dataset, labels,featLabels):\n",
    "    # 递归生成决策树\n",
    "    classList = [sample[-1] for sample in dataset]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataset[0])==1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataset)\n",
    "    bestFeatLable = labels[bestFeat]\n",
    "    featLabels.append(bestFeatLable)\n",
    "    myTree = {bestFeatLable:{}}\n",
    "    del labels[bestFeat]\n",
    "    featValue = [sample[bestFeat] for sample in dataset]\n",
    "    uniqueVals = set(featValue)\n",
    "    for value in uniqueVals:\n",
    "        sublabels = labels[:]\n",
    "        myTree[bestFeatLable][value]=creatTree(splitDataSet(dataset, bestFeat, value),sublabels)\n",
    "\n",
    "    return myTree\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    sorted_classCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sorted_classCount[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建决策树类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, \n",
    "                 value=None, left=None, right=None):\n",
    "        self.feature_index = feature_index   # 特征索引\n",
    "        self.threshold = threshold           # 分割阈值\n",
    "        self.value = value                   # 结点值\n",
    "        self.left = left                     # 左子结点\n",
    "        self.right = right                   # 右子结点\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "    def _gini_index(self, y):\n",
    "        classes = np.unique(y)\n",
    "        gini = 0.0\n",
    "        for cls in classes:\n",
    "            p = np.sum(y == cls) / len(y)\n",
    "            gini += p * (1 - p)\n",
    "        return gini\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature_index = 0\n",
    "        best_threshold = 0\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            for threshold in np.unique(X[:, feature_index]):\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = X[:, feature_index] > threshold\n",
    "                gini = (len(y[left_mask]) * self._gini_index(y[left_mask])\n",
    "                        + len(y[right_mask]) * self._gini_index(y[right_mask])) / len(y)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature_index = feature_index\n",
    "                    best_threshold = threshold\n",
    "        return best_feature_index, best_threshold\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return DecisionNode(value=np.argmax(np.bincount(y)))\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = X[:, feature_index] > threshold\n",
    "        left = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        return DecisionNode(feature_index, threshold, left=left, right=right)\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, 0)\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        for sample in X:\n",
    "            node = self.tree\n",
    "            while node.left:\n",
    "                if sample[node.feature_index] <= node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            results.append(node.value)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用鸢尾花数据集进行实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 加载数据集\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 创建决策树分类器对象\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "# 拟合训练数据\n",
    "clf.fit(X_train, y_train)\n",
    "# 预测测试数据\n",
    "y_pred = clf.predict(X_test)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
